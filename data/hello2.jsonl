{"jobLink": "https://careers.cognizant.com/global-en/jobs/00066042671/azure-databricks-engineer/?source=JB-11500", "jobDescription": {"jobTitle": "Azure Databricks Engineer/Developer", "jobOverview": {"summary": "Senior Developer role (8 to 12 years of experience) specializing in Databricks, PySpark, and Azure Data. The role focuses on developing and optimizing scalable data solutions, enhancing data processing capabilities, and collaborating on data architectures.", "location": ["Toronto", "Ontario", "Canada", "Hybrid"], "employmentType": "Full-time", "experienceLevel": "Senior", "experienceYears": "8-12 years", "department": "Digital"}, "keyResponsibilities": ["Develop and implement scalable data solutions using Databricks and PySpark to enhance data processing capabilities.", "Collaborate with cross-functional teams to design and optimize data architectures on Azure Data platforms.", "Provide technical expertise in data integration and transformation processes to ensure seamless data flow.", "Analyze complex data sets to identify trends and insights that support business objectives.", "Ensure data quality and integrity through rigorous testing and validation procedures.", "Optimize performance of data pipelines to improve efficiency and reduce processing time.", "Document technical specifications and maintain comprehensive records of data processes.", "Troubleshoot and resolve data-related issues to minimize disruptions in data operations.", "Mentor junior developers to foster a culture of continuous learning and improvement.", "Participate in code reviews to ensure adherence to coding standards and best practices."], "requiredQualifications": {"technicalSkills": ["Extensive experience in Databricks, PySpark, and Azure Data", "Solid understanding of data integration and transformation processes", "Experience developing and optimizing data solutions"], "toolsAndTechnologies": ["Databricks", "PySpark", "Azure Data Platforms"], "keyCompetencies": ["Strong problem-solving skills with the ability to troubleshoot complex data issues", "Excellent communication skills for effective collaboration with cross-functional teams", "Commitment to continuous learning, staying updated with the latest data technologies", "Proactive approach to optimizing data solutions"], "educationAndExperience": ["8 to 12 years of experience, specializing in Databricks, PySpark, and Azure Data"]}, "preferredQualifications": ["Experience in Life and Annuities Insurance"], "aboutCompany": {"name": "Cognizant", "description": "A company dedicated to fostering an energetic, collaborative, and inclusive workplace. Cognizant supports a healthy work-life balance and focuses on driving innovation."}}}
{"jobLink": "https://careers.cognizant.com/global-en/jobs/00066368911/databricks-python/", "jobDescription": {"jobTitle": "Databricks Python", "jobOverview": {"summary": "A Python and Databricks engineering role focused on designing, developing, and maintaining scalable data pipelines using Apache Spark. Responsibilities include optimizing Spark jobs, ensuring data quality, and implementing CI/CD and best practices in the Databricks environment.", "location": ["Coimbatore", "Tamil Nadu", "India", "Hybrid"], "employmentType": "Full-time", "experienceLevel": "Not Specified", "experienceYears": "Not Specified", "department": "Technology & Engineering"}, "keyResponsibilities": ["Design, develop, and maintain scalable data pipelines using Databricks and Apache Spark.", "Write efficient Python code for data processing, transformation, and automation tasks.", "Integrate data from multiple sources and ensure data quality and consistency.", "Optimize Spark jobs for performance and cost efficiency in Databricks environment.", "Collaborate with data scientists, analysts, and business stakeholders to deliver data solutions.", "Implement best practices for CI/CD, version control, and code deployment in Databricks.", "Monitor and troubleshoot data workflows and resolve production issues."], "requiredQualifications": {"technicalSkills": ["Python development for data processing and automation", "Scalable data pipeline design and development", "Data integration and transformation processes"], "toolsAndTechnologies": ["Databricks", "Apache Spark", "CI/CD and Version Control (implementation experience)"], "keyCompetencies": ["Ability to optimize Spark jobs for performance and cost efficiency", "Strong collaboration skills with cross-functional teams (data scientists, analysts, stakeholders)", "Proficiency in monitoring and troubleshooting data workflows", "Commitment to implementing coding and deployment best practices"], "educationAndExperience": ["Experience in designing, developing, and maintaining scalable data pipelines in Databricks", "Experience writing efficient, production-grade Python code"]}, "preferredQualifications": ["Not Specified"], "aboutCompany": {"name": "Cognizant", "description": "One of the world's leading professional services companies, transforming clients' business, operating, and technology models for the digital era. Focused on fostering an energetic, collaborative, and inclusive workplace."}}}